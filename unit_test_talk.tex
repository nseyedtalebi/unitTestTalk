\documentclass{beamer}

\usepackage{default}
\usepackage{csquotes}[]


\begin{document}
\author{Nima Seyedtalebi}
\title{Is Unit Testing Worth The Trouble?}
%\logo{}
\institute{University of Kentucky}
\date{November 7, 2018}
%\subject{}
%\setbeamercovered{transparent}
%\setbeamertemplate{navigation symbols}{}

\begin{frame}[plain]
\maketitle
\end{frame}

\begin{frame}
\frametitle{Background}
\begin{itemize}
	\item The IEEE Software Engineering Body of Knowledge (SWEBOK) provides a concise definition of software testing:
	
		\blockcquote{SWEBOK}{Software testing consists of the \textit{dynamic} verification that a program provides \textit{expected} behaviors on a \textit{finite} set of test cases, suitably \textit{selected} from the usually infinite execution}
 	\item Key points:
	\begin{itemize}
 		\item Dynamic: Input and source code are not always enough to determine behavior
 		\begin{itemize}
 			\item Examples: I/O, SLF4J
 		\end{itemize}
		\item Expected: We must be able to define expected behavior to test for it
 		\item Finite: The set of possible test cases is practically infinite, so we must choose a finite subset
 		\item Selected: Test cases can vary in usefulness considerably, so the choice is important
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Different Kinds of Testing}
\begin{itemize}
	\item Testing can be classified by target or objective
	\item Classifying by target gives three levels:
	\begin{itemize}
		\item Unit Testing: Small pieces of software testable in isolation
		\item Integration Testing: Interactions between software components
		\item System Testing: An entire system
	\end{itemize}
	\item Classifications by objective: 
	\begin{itemize}
		\item Regression testing
		\item Acceptance testing
		\item Security testing
		\item Performance testing
		\item Stress testing
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{What is Unit Testing?}
\begin{itemize}
	\item From the SWEBOK:\blockcquote{SWEBOK}{Unit testing verifies the functioning in isolation of software elements that are separately testable.}
	\begin{itemize}
 		\item What constitutes a unit? It depends on context
 		\item Developers may have differing ideas about what constitutes a unit
	\end{itemize}
	\item Usually performed by the developer of the unit or someone with programming skills and access to the source code
	\item Surveys suggest unit testing is an important testing method that sees widespread use
	\item Unit testing is sometimes conflated with other kinds of testing
	\begin{itemize}
		\item E.g. a "unit test" that relies on a database connection is not a unit test under the definition given
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Testing Terms and Software Metrics}
\begin{itemize}
	\item Failure: An undesired behavior
	\item Fault: The cause of a failure
	\item Defect: A fault or failure
	\item General software measures:
	\begin{itemize}
		\item Code size (lines of code)
		\item Number of independent paths through code (cyclomatic complexity)
		\item Degree of nesting
		\item Average number of parameters
		\item Fan-out, or how many classes does this class use?
		\item Fan-in, or how many classes use this class?
	\end{itemize}
	\item Survey data are used to measure things that are difficult to measure objectively
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Challenges in Software Testing}
\begin{itemize}
	\item Tests that are written without referring to some external specification can only suggest that the code does what the developer intended
	\item Exhaustive testing is impractical at best and impossible at worst. Consider a program similar to "echo" in Unix that takes a Unicode string argument:
	\begin{itemize}
		\item With Unicode 11, $137374^n$ permutations of length $n$ are possible\cite{unicodestd}
	\end{itemize}
	\item Some tests are more useful than others. How do we choose the best set of tests?
	\item How do we know if we have enough tests?
	\item How do we know if testing is effective?
	\item Testing always involves a trade-off. More tests may find more problems, but tests take time to write and maintain
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Common Techniques for Choosing a Test Set}
\begin{itemize}
	\item Ad-hoc: Choose test inputs based on intuition and experience
	\item Boundary-value Analysis: Choose inputs close to boundaries in the input domain e.g. largest and smallest possible values for numerical datatypes
	\item Code-based analysis techniques:
	\begin{itemize}
		\item Control Flow Analysis: Choose tests that follow a subset of the possible control flow paths through the code
		\item Data Flow Analysis: Choose tests that follow a subset of the possible data flow paths through the code
		\item Mutation Analysis: Choose tests that fail when the program under test is changed slightly
	\end{itemize}
	\item The code-based techniques are often used to assess test sufficiency
\end{itemize}
\end{frame}

%\begin{frame}
%\frametitle{Code Quality and Test Sufficiency}
%	\begin{itemize}
%	\item Test quality, test sufficiency, and the quality of the software under test are distinct
%\item Measures of quality:
%\begin{itemize}
%	\item Fault classification, count, and density
%\end{itemize}
%\item Measures of test sufficiency:
%\begin{itemize}
%	\item Coverage, often expressed as a percentage
%	\item Mutation score
%\end{itemize}
%\item The number of defects detected by a test suite can serve as a measure of test quality or sufficiency
%\begin{itemize}
%	\item Quality: Test suite A is better than suite B because it found more bugs
%	\item Sufficiency: Test suite A is sufficient because it found at least $n$ bugs
%\end{itemize}
%\end{itemize}
%\end{frame}

\begin{frame}
\frametitle{Control-Flow and Data-Flow Analysis}
	\begin{itemize}
	\item Units contain assignment statements and conditional statements
	\item Units have well-defined entry and exit points
	\item A \textit{path} is a sequence of instructions
	\item Conditional statements determine control flow
	\item Assignment statements determine data flow
	\item Control-flow and data-flow analysis both involve selecting tests so their execution follows different paths through the code
	\item They differ in perspective and how paths are selected:
	\begin{itemize}
		\item Control flow analysis considers paths between the entry and exit points
		\item Data flow analysis considers paths that start with an assignment statement and end with the last use of the variable
	\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Coverage Metrics}
\begin{itemize}
	\item Coverage metrics assess how many execution paths are tested versus how many are possible
	\item Metrics are based on desired level of coverage \item More complete coverage means exploring a larger portion of the possible execution paths
	\item Path selection criteria for control-flow analysis:
	\begin{itemize}
		\item Statement Coverage: All statements are executed at least once
		\item Branch Coverage: Every branch is taken at least once
		\item Predicate Coverage: Every combination of truth value for every conditional is tried at least once
		\item All-Paths Coverage: Every execution path is tried at least once
	\end{itemize}
	\item Path selection criteria for data-flow analysis are based on when variables are defined and used
\end{itemize}
\end{frame}
%I can add a slide for details on data flow analysis if needed
\begin{frame}
\frametitle{Mutation Analysis}
\begin{itemize}
	\item Mutation score comes from mutation analysis, first proposed in a 1978 article "Hints on Test Data Selection"\cite{hintsOnTestData}
	\item Key insights:
	\begin{itemize}
		\item Programmers usually write software that is "almost correct"
		\item Finding simple errors uncovers complex errors
	\end{itemize}
	\item Used to assess test data sufficiency
	\item Mutation analysis involves making small, syntactically-legal changes to the unit under test, producing \textit{mutants}
	\begin{itemize}
		\item If the mutant causes some test to fail, it is said to be \textit{dead}
		\item If the mutant does not cause any tests to fail, it is said to be \textit{alive},\textit{killable}, or \textit{stubborn}
		\item Mutants are killed when the test set is sufficiently sensitive to detect the mutation
	\end{itemize}
	\item Mutation score is the number of mutants killed divided by the total number of mutants
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{What Does a Good Test Look Like?}
\begin{itemize}
	\item Bowes et al.\cite{howGoodAreMyTests} wrote a paper called "How Good Are My Tests" that contained fifteen principles to follow when writing unit tests
	\item Some of them include:
	\begin{itemize}
		\item "Simplicity"
		\item "Readability and Comprehension"
		\item "Single-responsibility" (fail for one reason)
		\item "Avoid over-protectiveness" (e.g. redundant assertions)
		\item "Test behavior (not implementation)"
		\item "Tests should not dictate the code"
		\item "A test should fail." Tests that never fail are useless
		\item "Reliability", and no nondeterminism
		\item "Happy vs. sad tests"
		\begin{itemize}
			\item "Happy" tests verify system behavior
			\item "Sad" tests break the system
			\item Both are useful, but confirmation bias creeps in and causes us to favor "happy" tests
		\end{itemize}
		
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Arguments for Unit Testing}
\begin{itemize}
	\item Helps uncover defects early in the development process
	\item Allows developers to refactor with confidence because breaking changes will cause the tests to fail
	\item Can encourage good software design
	\begin{itemize}
		\item Unit testing requires the unit under test (UUT) to be isolated
		\item Tightly-coupled units require more effort to test
		\item Tightly-coupled units are less robust
		\item Difficulty or undue effort in testing indicates suggest code needs refactoring to reduce coupling
	\end{itemize}
	\item Tests serve as a form of documentation
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Arguments Against, or Unit Testing Considered Harmful}
\begin{itemize}
	\item Unit testing does not positively affect code quality in practice
	\begin{itemize}
		\item Most tests only assess whether the code does what the developer intended
		\item Developers write lower-quality code to meet coverage-based requirements
	\end{itemize}
	\item Low-quality tests are worse than no tests at all since they must be maintained
	\item Unit tests provide a false sense of security
	\item Unit testing costs more time than it saves
	\item Integration and system testing are more effective at uncovering defects
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{What Does the Research Say?}
\begin{itemize}
	\item No correlation found yet between unit testing and code quality\cite{codeQual}
	\item No correlation found between coverage-based methods for determining test sufficiency  quality and code quality\cite{codeQual}
	\item Developers need a better understanding of what makes a unit test good\cite{unitTestSurv}
	\item Test-Driven Development (TDD), of which unit testing is an integral part, seems to measurably improve software quality in some cases\cite{tddMeta},\cite{doesTDDWork}
	\item Automated test generation is in use, but mostly used in cases where specifications are not required\cite{unitTestSurv}
\end{itemize}
\end{frame}


%\begin{frame}
%\frametitle{Limitations of Unit Testing}
%\begin{itemize}
%	\item Cannot detect faults in the interaction between units or between subsystems
%	\item Add to the complexity of the software under development
%	\begin{itemize}
%		\item Bad unit tests have costs beyond the time to write them
%		\item Good unit tests that are hard to maintain may be worse than no unit tests at all
%	\end{itemize}
%	\item Any test can contain defects
%	\item Cover only a tiny fraction of the state space
%\end{itemize}
%\end{frame}

\begin{frame}
\frametitle{What About Test-Driven Development?}
\begin{itemize}
	\item Test-driven development (TDD) is a development style built around two rules:\cite{tddByExample}
	\begin{itemize}
		\item "Write new code only if you first have a failing automated test"
		\item "Eliminate duplication"
	\end{itemize}
	\item Important points:
	\begin{itemize}
		\item Test: Unit tests are written before new code
		\item Failing: The test must fail at first
		\item Automated: Tools are used to run tests and collect results
	\end{itemize}
	\item "The goal is clean code that works..."\cite{tddByExample}
	\begin{itemize}
		\item Clean code has the smallest possible number of dependencies
		\item Empirical studies of TDD use different measures
		\item The ambiguity was probably intentional\footnote{\textit{Test-Driven Development By Example} says,"TDD is an awareness of the gap between decision and feedback during programming,and techniques to control that gap"}
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{...and the Research?}
\begin{itemize}
	\item A 2008 article \cite{doesTDDWork} found modest improvements in code size and complexity but not in coupling or cohesion
	\item A 2013 meta-analysis\cite{tddMeta} of 27 empirical studies found that TDD "results in a small improvement in quality but results on productivity are inconclusive."
	\item A recent (July 2018) article\cite{whatWeKnowTDD} called "What Do We (Really) Know About Test-Driven Development?" offers the following:
	\begin{itemize}
		\item Use of TDD is uncommon in practice
		\item TDD does appear to improve some measures of quality in some cases
		\item Evidence for the effects of TDD on productivity is inconclusive 
		\item The order of testing is not the important part of TDD
		\item Using a short development cycle had much more impact on quality than the order of testing (test-first versus test-last)
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Conclusions}
\begin{itemize}
	\item Unit testing \textit{can} be worth the trouble, but it is not sufficient by itself to improve software quality
	\item An iterative development process with short, gradual steps seems to improve software quality
	\item Unit testing and TDD are tools. Like other tools, they work best in the hands of those that know how to use them
	\item Test quality is very important since we are limited to a very small subset of possibilities when testing
	\item Testing is a balancing act
	\begin{itemize}
		\item Test selection is an important problem
		\item Tests are not free to maintain, even if a machine writes them for you
	\end{itemize}
	\item Automation and tool support is a poor substitute for thinking about design
\end{itemize}
\end{frame}	

\begin{frame}
\frametitle{So What Can Be Done?}
\begin{itemize}
\item "A Survey On Unit Testing Practice and Problems"\cite{unitTestSurv} suggests:
\begin{itemize}
	\item Developers need help identifying what to test and whether a given test is good or not
	\item Automatic  test generation helps with the "how" of testing but not the "what"
	\item The question of "what" is shared across all types of testing
	\item Tests should be realistic
\end{itemize}
\item Furthermore:
\begin{itemize}
	\item Software design is a skill that must be learned and practiced 
	\item Though part of design, testing is a distinct skill that must be learned and practiced
\end{itemize}
\end{itemize}
\end{frame}
References:

	\nocite{*}
	\bibliographystyle{plain}
	\bibliography{unit_test_talk}

\end{document}
